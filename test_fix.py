#!/usr/bin/env python3
"""
éªŒè¯æœ€ä½³ç¨‹åºä¿å­˜æœºåˆ¶ä¿®å¤çš„æµ‹è¯•è„šæœ¬
"""

import json
import os
import sys

def load_program_info(path):
    """åŠ è½½ç¨‹åºä¿¡æ¯"""
    try:
        with open(path, 'r') as f:
            return json.load(f)
    except Exception as e:
        print(f"åŠ è½½ {path} å¤±è´¥: {e}")
        return None

def main():
    """ä¸»å‡½æ•°"""
    output_dir = "openevolve_output"
    
    print("ğŸ” éªŒè¯æœ€ä½³ç¨‹åºä¿å­˜æœºåˆ¶ä¿®å¤æ•ˆæœ")
    print("=" * 60)
    
    # æ£€æŸ¥æ ¹ç›®å½•çš„æœ€ä½³ç¨‹åº
    best_info = load_program_info(os.path.join(output_dir, "best", "best_program_info.json"))
    if best_info:
        print(f"ğŸ“‚ æ ¹ç›®å½•æœ€ä½³ç¨‹åº:")
        print(f"   ID: {best_info['id']}")
        print(f"   æ‰¾åˆ°è½®æ¬¡: {best_info['iteration']}")
        print(f"   è¯„åˆ†: {best_info['metrics'].get('combined_score', 'N/A')}")
        print(f"   æˆåŠŸç‡: {best_info['metrics'].get('success_rate', 'N/A')}")
    
    # æ£€æŸ¥ä¿®å¤ç‰ˆæœ¬
    fixed_info = load_program_info(os.path.join(output_dir, "best", "best_program_info_fixed.json"))
    if fixed_info:
        print(f"ğŸ”§ ä¿®å¤ç‰ˆæœ¬æœ€ä½³ç¨‹åº:")
        print(f"   ID: {fixed_info['id']}")
        print(f"   æ‰¾åˆ°è½®æ¬¡: {fixed_info['iteration']}")
        print(f"   è¯„åˆ†: {fixed_info['metrics'].get('combined_score', 'N/A')}")
        print(f"   æˆåŠŸç‡: {fixed_info['metrics'].get('success_rate', 'N/A')}")
    
    # æ‰«ææ‰€æœ‰æ£€æŸ¥ç‚¹æ‰¾åˆ°çœŸæ­£çš„æœ€ä½³
    print(f"\nğŸ” æ‰«ææ‰€æœ‰æ£€æŸ¥ç‚¹:")
    checkpoints_dir = os.path.join(output_dir, "checkpoints")
    best_overall = None
    best_score = -1
    
    if os.path.exists(checkpoints_dir):
        for checkpoint in sorted(os.listdir(checkpoints_dir)):
            if checkpoint.startswith("checkpoint_"):
                info_path = os.path.join(checkpoints_dir, checkpoint, "best_program_info.json")
                info = load_program_info(info_path)
                if info and 'combined_score' in info['metrics']:
                    score = info['metrics']['combined_score']
                    iteration = checkpoint.split("_")[1]
                    print(f"   æ£€æŸ¥ç‚¹ {iteration}: è¯„åˆ† {score:.4f}, æˆåŠŸç‡ {info['metrics'].get('success_rate', 'N/A')}")
                    
                    if score > best_score:
                        best_score = score
                        best_overall = (checkpoint, info)
    
    print(f"\nğŸ† çœŸæ­£çš„å†å²æœ€ä½³:")
    if best_overall:
        checkpoint, info = best_overall
        print(f"   ä½ç½®: {checkpoint}")
        print(f"   ID: {info['id']}")
        print(f"   æ‰¾åˆ°è½®æ¬¡: {info['iteration']}")
        print(f"   è¯„åˆ†: {info['metrics'].get('combined_score', 'N/A'):.4f}")
        print(f"   æˆåŠŸç‡: {info['metrics'].get('success_rate', 'N/A')}")
        
        # æ¯”è¾ƒæ ¹ç›®å½•å’ŒçœŸæ­£æœ€ä½³çš„å·®å¼‚
        if best_info and 'combined_score' in best_info['metrics']:
            root_score = best_info['metrics']['combined_score']
            diff = best_score - root_score
            print(f"\nğŸ“Š æ€§èƒ½å·®å¼‚åˆ†æ:")
            print(f"   æ ¹ç›®å½•ä¿å­˜çš„è¯„åˆ†: {root_score:.4f}")
            print(f"   çœŸæ­£çš„æœ€ä½³è¯„åˆ†: {best_score:.4f}")
            print(f"   æ€§èƒ½æŸå¤±: {diff:.4f} ({diff/best_score*100:.1f}%)")
            
            if diff > 0.01:
                print(f"   âŒ ç¡®è®¤å­˜åœ¨bug: æ ¹ç›®å½•ä¿å­˜äº†é”™è¯¯çš„ç¨‹åº!")
            else:
                print(f"   âœ… æ ¹ç›®å½•ä¿å­˜æ­£ç¡®")
    
    print(f"\nğŸ› ï¸  ä¿®å¤å»ºè®®:")
    print(f"   1. ä½¿ç”¨ checkpoints/checkpoint_10/best_program.py ä½œä¸ºçœŸæ­£çš„æœ€ä½³ç‰ˆæœ¬")
    print(f"   2. ä»£ç ä¿®å¤å·²å®Œæˆï¼Œä¸‹æ¬¡è¿è¡Œåº”è¯¥ä¼šæ­£ç¡®ä¿å­˜")
    print(f"   3. å¯ä»¥è¿è¡Œ 'cp checkpoints/checkpoint_10/best_program.py best/best_program.py' æ‰‹åŠ¨ä¿®å¤")

if __name__ == "__main__":
    main() 