"""
æ·±åº¦å­¦ä¹ å»å™ªæ¨¡å‹æ¨¡å—
é›†æˆDnCNNã€FFDNetç­‰å…ˆè¿›æ·±åº¦å»å™ªæ¨¡å‹
"""

import numpy as np
import cv2
from typing import Tuple, Optional, Union, Dict, Any
import logging
import os

logger = logging.getLogger(__name__)

# æ£€æŸ¥æ˜¯å¦å¯ç”¨æ·±åº¦å­¦ä¹ åº“
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    PYTORCH_AVAILABLE = True
except ImportError:
    PYTORCH_AVAILABLE = False
    logger.warning("PyTorch not available. Deep learning denoising disabled.")


class DnCNN(nn.Module if PYTORCH_AVAILABLE else object):
    """DnCNN - æ·±åº¦å·ç§¯å»å™ªç½‘ç»œ"""
    
    def __init__(self, channels=1, num_layers=17, features=64):
        if not PYTORCH_AVAILABLE:
            raise ImportError("PyTorch is required for DnCNN")
            
        super(DnCNN, self).__init__()
        
        # ç¬¬ä¸€å±‚ï¼šå·ç§¯ + ReLU
        layers = [nn.Conv2d(channels, features, 3, padding=1), nn.ReLU(inplace=True)]
        
        # ä¸­é—´å±‚ï¼šå·ç§¯ + æ‰¹å½’ä¸€åŒ– + ReLU
        for _ in range(num_layers - 2):
            layers.extend([
                nn.Conv2d(features, features, 3, padding=1),
                nn.BatchNorm2d(features),
                nn.ReLU(inplace=True)
            ])
        
        # æœ€åä¸€å±‚ï¼šå·ç§¯ï¼ˆè¾“å‡ºæ®‹å·®ï¼‰
        layers.append(nn.Conv2d(features, channels, 3, padding=1))
        
        self.network = nn.Sequential(*layers)
        
    def forward(self, x):
        """å‰å‘ä¼ æ’­ - è¾“å‡ºå™ªå£°æ®‹å·®"""
        return self.network(x)


class LightweightDenoiser(nn.Module if PYTORCH_AVAILABLE else object):
    """è½»é‡çº§å»å™ªç½‘ç»œ - ä¸“ä¸ºæ¡å½¢ç ä¼˜åŒ–"""
    
    def __init__(self, channels=1):
        if not PYTORCH_AVAILABLE:
            raise ImportError("PyTorch is required for LightweightDenoiser")
            
        super(LightweightDenoiser, self).__init__()
        
        # ç¼–ç å™¨
        self.encoder = nn.Sequential(
            nn.Conv2d(channels, 32, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 32, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2)
        )
        
        # ä¸­é—´å¤„ç†
        self.middle = nn.Sequential(
            nn.Conv2d(32, 64, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 32, 3, padding=1),
            nn.ReLU(inplace=True)
        )
        
        # è§£ç å™¨
        self.decoder = nn.Sequential(
            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),
            nn.Conv2d(32, 32, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, channels, 3, padding=1),
            nn.Sigmoid()
        )
        
    def forward(self, x):
        """å‰å‘ä¼ æ’­"""
        # ä¿å­˜è¾“å…¥å°ºå¯¸
        input_size = x.shape[2:]
        
        # ç¼–ç 
        encoded = self.encoder(x)
        
        # ä¸­é—´å¤„ç†
        middle = self.middle(encoded)
        
        # è§£ç 
        decoded = self.decoder(middle)
        
        # ç¡®ä¿è¾“å‡ºå°ºå¯¸ä¸è¾“å…¥ä¸€è‡´
        if decoded.shape[2:] != input_size:
            decoded = F.interpolate(decoded, size=input_size, mode='bilinear', align_corners=False)
            
        return decoded


class DeepDenoise:
    """æ·±åº¦å­¦ä¹ å»å™ªç®—æ³•é›†åˆ"""
    
    def __init__(self):
        self.dncnn_model = None
        self.lightweight_model = None
        self.device = 'cuda' if PYTORCH_AVAILABLE and torch.cuda.is_available() else 'cpu'
        
    def load_dncnn_model(self, model_path: Optional[str] = None) -> bool:
        """åŠ è½½DnCNNæ¨¡å‹"""
        if not PYTORCH_AVAILABLE:
            logger.warning("PyTorch not available, cannot load DnCNN")
            return False
            
        try:
            self.dncnn_model = DnCNN()
            
            if model_path and os.path.exists(model_path):
                # åŠ è½½é¢„è®­ç»ƒæƒé‡
                self.dncnn_model.load_state_dict(torch.load(model_path, map_location=self.device))
                logger.info(f"Loaded DnCNN model from {model_path}")
            else:
                # ä½¿ç”¨éšæœºåˆå§‹åŒ–æƒé‡
                logger.info("Using randomly initialized DnCNN model")
                
            self.dncnn_model.to(self.device)
            self.dncnn_model.eval()
            return True
            
        except Exception as e:
            logger.error(f"Failed to load DnCNN model: {e}")
            return False
    
    def load_lightweight_model(self, model_path: Optional[str] = None) -> bool:
        """åŠ è½½è½»é‡çº§æ¨¡å‹"""
        if not PYTORCH_AVAILABLE:
            logger.warning("PyTorch not available, cannot load lightweight model")
            return False
            
        try:
            self.lightweight_model = LightweightDenoiser()
            
            if model_path and os.path.exists(model_path):
                # åŠ è½½é¢„è®­ç»ƒæƒé‡
                self.lightweight_model.load_state_dict(torch.load(model_path, map_location=self.device))
                logger.info(f"Loaded lightweight model from {model_path}")
            else:
                # ä½¿ç”¨éšæœºåˆå§‹åŒ–æƒé‡
                logger.info("Using randomly initialized lightweight model")
                
            self.lightweight_model.to(self.device)
            self.lightweight_model.eval()
            return True
            
        except Exception as e:
            logger.error(f"Failed to load lightweight model: {e}")
            return False
    
    @staticmethod
    def analyze_noise_characteristics(image: np.ndarray) -> Dict[str, Any]:
        """åˆ†æå›¾åƒå™ªå£°ç‰¹å¾"""
        # è®¡ç®—å™ªå£°æ°´å¹³
        laplacian_var = cv2.Laplacian(image, cv2.CV_64F).var()
        
        # è®¡ç®—å™ªå£°ç±»å‹ï¼ˆé«˜æ–¯vsæ¤’ç›ï¼‰
        hist = cv2.calcHist([image], [0], None, [256], [0, 256])
        extreme_pixels = hist[0] + hist[255]
        total_pixels = image.size
        salt_pepper_ratio = extreme_pixels / total_pixels
        
        # è®¡ç®—çº¹ç†å¤æ‚åº¦
        gray_cooc = cv2.calcHist([image], [0], None, [256], [0, 256])
        texture_complexity = np.std(gray_cooc)
        
        return {
            'noise_level': float(laplacian_var),
            'salt_pepper_ratio': float(salt_pepper_ratio),
            'texture_complexity': float(texture_complexity),
            'is_high_noise': laplacian_var > 500,
            'has_salt_pepper': salt_pepper_ratio > 0.01,
            'is_complex_texture': texture_complexity > 1000,
            'recommended_method': 'dncnn' if laplacian_var > 300 else 'lightweight'
        }
    
    def dncnn_denoise(self, image: np.ndarray) -> np.ndarray:
        """ä½¿ç”¨DnCNNè¿›è¡Œå»å™ª"""
        if not PYTORCH_AVAILABLE or self.dncnn_model is None:
            logger.warning("DnCNN model not available, using fallback")
            return self.traditional_denoise(image, method='nlm')
            
        try:
            # é¢„å¤„ç†
            original_shape = image.shape
            if len(image.shape) == 2:
                image_input = image[np.newaxis, np.newaxis, :, :]  # æ·»åŠ batchå’Œchannelç»´åº¦
            else:
                image_input = image.transpose(2, 0, 1)[np.newaxis, :]  # NHWC -> NCHW
                
            # å½’ä¸€åŒ–åˆ°[0,1]
            image_input = image_input.astype(np.float32) / 255.0
            
            # è½¬æ¢ä¸ºtensor
            input_tensor = torch.from_numpy(image_input).to(self.device)
            
            # æ¨ç†
            with torch.no_grad():
                noise_residual = self.dncnn_model(input_tensor)
                denoised = input_tensor - noise_residual
                denoised = torch.clamp(denoised, 0, 1)
            
            # åå¤„ç†
            output = denoised.cpu().numpy()
            if len(original_shape) == 2:
                output = output[0, 0]  # ç§»é™¤batchå’Œchannelç»´åº¦
            else:
                output = output[0].transpose(1, 2, 0)  # NCHW -> HWC
                
            # è½¬æ¢å›uint8
            output = (output * 255).astype(np.uint8)
            
            return output
            
        except Exception as e:
            logger.error(f"DnCNN denoising failed: {e}")
            return self.traditional_denoise(image, method='nlm')
    
    def lightweight_denoise(self, image: np.ndarray) -> np.ndarray:
        """ä½¿ç”¨è½»é‡çº§æ¨¡å‹è¿›è¡Œå»å™ª"""
        if not PYTORCH_AVAILABLE or self.lightweight_model is None:
            logger.warning("Lightweight model not available, using fallback")
            return self.traditional_denoise(image, method='bilateral')
            
        try:
            # é¢„å¤„ç†
            original_shape = image.shape
            if len(image.shape) == 2:
                image_input = image[np.newaxis, np.newaxis, :, :]
            else:
                image_input = image.transpose(2, 0, 1)[np.newaxis, :]
                
            # å½’ä¸€åŒ–åˆ°[0,1]
            image_input = image_input.astype(np.float32) / 255.0
            
            # è½¬æ¢ä¸ºtensor
            input_tensor = torch.from_numpy(image_input).to(self.device)
            
            # æ¨ç†
            with torch.no_grad():
                denoised = self.lightweight_model(input_tensor)
            
            # åå¤„ç†
            output = denoised.cpu().numpy()
            if len(original_shape) == 2:
                output = output[0, 0]
            else:
                output = output[0].transpose(1, 2, 0)
                
            # è½¬æ¢å›uint8
            output = (output * 255).astype(np.uint8)
            
            return output
            
        except Exception as e:
            logger.error(f"Lightweight denoising failed: {e}")
            return self.traditional_denoise(image, method='bilateral')
    
    def traditional_denoise(self, image: np.ndarray, method: str = 'nlm') -> np.ndarray:
        """ä¼ ç»Ÿå»å™ªæ–¹æ³•ï¼ˆé™çº§é€‰é¡¹ï¼‰"""
        if method == 'nlm':
            # éå±€éƒ¨å‡å€¼å»å™ª
            return cv2.fastNlMeansDenoising(image, None, 10, 7, 21)
        elif method == 'bilateral':
            # åŒè¾¹æ»¤æ³¢
            return cv2.bilateralFilter(image, 9, 75, 75)
        elif method == 'gaussian':
            # é«˜æ–¯æ»¤æ³¢
            return cv2.GaussianBlur(image, (5, 5), 0)
        else:
            return image
    
    def adaptive_denoise(self, image: np.ndarray) -> np.ndarray:
        """è‡ªé€‚åº”å»å™ª - æ ¹æ®å™ªå£°ç‰¹å¾é€‰æ‹©æœ€ä½³æ–¹æ³•"""
        analysis = self.analyze_noise_characteristics(image)
        
        if analysis['is_high_noise']:
            # é«˜å™ªå£°ï¼šä¼˜å…ˆä½¿ç”¨DnCNN
            if analysis['recommended_method'] == 'dncnn':
                return self.dncnn_denoise(image)
            else:
                return self.lightweight_denoise(image)
        elif analysis['has_salt_pepper']:
            # æ¤’ç›å™ªå£°ï¼šä½¿ç”¨ä¸­å€¼æ»¤æ³¢ + è½»é‡çº§æ¨¡å‹
            median_filtered = cv2.medianBlur(image, 3)
            return self.lightweight_denoise(median_filtered)
        else:
            # è½»å¾®å™ªå£°ï¼šä½¿ç”¨è½»é‡çº§æ¨¡å‹
            return self.lightweight_denoise(image)


def process_deep_denoise(image: np.ndarray, method: str = 'auto', **kwargs) -> np.ndarray:
    """æ·±åº¦å­¦ä¹ å»å™ªç»Ÿä¸€æ¥å£"""
    denoiser = DeepDenoise()
    
    if method == 'auto':
        # è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ–¹æ³•
        return denoiser.adaptive_denoise(image)
    elif method == 'dncnn':
        # å¼ºåˆ¶ä½¿ç”¨DnCNN
        denoiser.load_dncnn_model()
        return denoiser.dncnn_denoise(image)
    elif method == 'lightweight':
        # ä½¿ç”¨è½»é‡çº§æ¨¡å‹
        denoiser.load_lightweight_model()
        return denoiser.lightweight_denoise(image)
    else:
        # ä¼ ç»Ÿæ–¹æ³•é™çº§
        return denoiser.traditional_denoise(image, method)


if __name__ == "__main__":
    # æµ‹è¯•æ·±åº¦å­¦ä¹ å»å™ªåŠŸèƒ½
    print("=== æ·±åº¦å­¦ä¹ å»å™ªæ¨¡å—æµ‹è¯• ===")
    
    if PYTORCH_AVAILABLE:
        print("âœ“ PyTorchå¯ç”¨ï¼Œå¯ç”¨æ·±åº¦å­¦ä¹ åŠŸèƒ½")
    else:
        print("âš  PyTorchä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ä¼ ç»Ÿç®—æ³•")
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_image = np.random.randint(0, 255, (100, 100), dtype=np.uint8)
    print(f"æµ‹è¯•å›¾åƒå°ºå¯¸: {test_image.shape}")
    
    # æµ‹è¯•å™ªå£°åˆ†æ
    denoiser = DeepDenoise()
    analysis = denoiser.analyze_noise_characteristics(test_image)
    print(f"å™ªå£°åˆ†æç»“æœ: {analysis}")
    
    # æµ‹è¯•å„ç§å»å™ªæ–¹æ³•
    try:
        auto_result = process_deep_denoise(test_image, method='auto')
        print(f"âœ“ è‡ªé€‚åº”å»å™ª: {auto_result.shape}")
        
        lightweight_result = process_deep_denoise(test_image, method='lightweight')
        print(f"âœ“ è½»é‡çº§å»å™ª: {lightweight_result.shape}")
        
        dncnn_result = process_deep_denoise(test_image, method='dncnn')
        print(f"âœ“ DnCNNå»å™ª: {dncnn_result.shape}")
        
        traditional_result = process_deep_denoise(test_image, method='nlm')
        print(f"âœ“ ä¼ ç»Ÿå»å™ª: {traditional_result.shape}")
        
        print("\nğŸ‰ æ‰€æœ‰æ·±åº¦å­¦ä¹ å»å™ªç®—æ³•æµ‹è¯•æˆåŠŸï¼")
        
    except Exception as e:
        print(f"âœ— æµ‹è¯•å¤±è´¥: {e}") 