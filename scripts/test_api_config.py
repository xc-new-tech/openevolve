#!/usr/bin/env python3
"""
OpenEvolve API é…ç½®æµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯ä¸åŒLLMæä¾›å•†çš„APIå¯†é’¥é…ç½®æ˜¯å¦æ­£ç¡®
"""

import asyncio
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# åŠ è½½.envæ–‡ä»¶
try:
    from dotenv import load_dotenv
    env_file = project_root / ".env"
    if env_file.exists():
        load_dotenv(env_file)
        print(f"âœ… å·²åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶: {env_file}")
    else:
        print(f"âš ï¸  æœªæ‰¾åˆ°.envæ–‡ä»¶: {env_file}")
except ImportError:
    print("âš ï¸  æœªå®‰è£…python-dotenvï¼Œå°è¯•å®‰è£…: pip install python-dotenv")
except Exception as e:
    print(f"âš ï¸  åŠ è½½.envæ–‡ä»¶æ—¶å‡ºé”™: {e}")

from openevolve.config import load_config, LLMModelConfig
from openevolve.llm.openai import OpenAILLM


def check_env_vars():
    """æ£€æŸ¥ç¯å¢ƒå˜é‡ä¸­çš„APIå¯†é’¥"""
    print("=== æ£€æŸ¥ç¯å¢ƒå˜é‡ ===")
    
    api_keys = {
        "OpenAI": "OPENAI_API_KEY",
        "Anthropic": "ANTHROPIC_API_KEY", 
        "Google": "GOOGLE_API_KEY",
        "Mistral": "MISTRAL_API_KEY",
        "OpenRouter": "OPENROUTER_API_KEY",
        "xAI": "XAI_API_KEY",
        "Azure OpenAI": "AZURE_OPENAI_API_KEY",
        "Perplexity": "PERPLEXITY_API_KEY",
    }
    
    found_keys = []
    for provider, env_var in api_keys.items():
        value = os.getenv(env_var)
        if value:
            # åªæ˜¾ç¤ºå¯†é’¥çš„å‰å‡ ä½å’Œåå‡ ä½
            masked = f"{value[:8]}...{value[-4:]}" if len(value) > 12 else "***"
            print(f"âœ… {provider}: {masked}")
            found_keys.append(provider)
        else:
            print(f"âŒ {provider}: æœªè®¾ç½®")
    
    if not found_keys:
        print("\nâš ï¸  æœªæ‰¾åˆ°ä»»ä½•APIå¯†é’¥ï¼è¯·è®¾ç½®è‡³å°‘ä¸€ä¸ªæä¾›å•†çš„APIå¯†é’¥ã€‚")
        return False
    
    print(f"\nâœ… æ‰¾åˆ° {len(found_keys)} ä¸ªAPIå¯†é’¥")
    return True


async def test_api_connection(provider, model_config):
    """æµ‹è¯•APIè¿æ¥"""
    try:
        print(f"\n--- æµ‹è¯• {provider} ---")
        llm = OpenAILLM(model_config)
        
        # å‘é€ç®€å•æµ‹è¯•è¯·æ±‚
        response = await llm.generate("è¯´'ä½ å¥½'", max_tokens=10)
        print(f"âœ… {provider} æµ‹è¯•æˆåŠŸ")
        print(f"   æ¨¡å‹: {model_config.name}")
        print(f"   å“åº”: {response.strip()}")
        return True
        
    except Exception as e:
        print(f"âŒ {provider} æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


async def test_config_file(config_path):
    """æµ‹è¯•é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®"""
    print(f"\n=== æµ‹è¯•é…ç½®æ–‡ä»¶: {config_path} ===")
    
    try:
        config = load_config(config_path)
        print(f"âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
        print(f"   è¯­è¨€: {config.language}")
        print(f"   æ¨¡å‹æ•°é‡: {len(config.llm.models)}")
        
        # æµ‹è¯•æ¯ä¸ªæ¨¡å‹
        success_count = 0
        for i, model in enumerate(config.llm.models):
            if model.name:
                provider = f"æ¨¡å‹{i+1} ({model.name})"
                success = await test_api_connection(provider, model)
                if success:
                    success_count += 1
        
        print(f"\nğŸ“Š æµ‹è¯•ç»“æœ: {success_count}/{len(config.llm.models)} ä¸ªæ¨¡å‹å¯ç”¨")
        return success_count > 0
        
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


def create_test_models():
    """åˆ›å»ºæµ‹è¯•æ¨¡å‹é…ç½®"""
    test_models = []
    
    # OpenAI
    if os.getenv("OPENAI_API_KEY"):
        test_models.append(LLMModelConfig(
            name="gpt-3.5-turbo",
            api_base="https://api.openai.com/v1",
            api_key=os.getenv("OPENAI_API_KEY"),
            temperature=0.7,
            max_tokens=50,
            timeout=30,
            retries=2,
            retry_delay=2
        ))
    
    # Google Gemini
    if os.getenv("GOOGLE_API_KEY"):
        test_models.append(LLMModelConfig(
            name="gemini-2.0-flash-lite", 
            api_base="https://generativelanguage.googleapis.com/v1beta/openai/",
            api_key=os.getenv("GOOGLE_API_KEY"),
            temperature=0.7,
            max_tokens=50,
            timeout=30,
            retries=2,
            retry_delay=2
        ))
    
    # Anthropic
    if os.getenv("ANTHROPIC_API_KEY"):
        test_models.append(LLMModelConfig(
            name="claude-3-haiku-20240307",
            api_base="https://api.anthropic.com", 
            api_key=os.getenv("ANTHROPIC_API_KEY"),
            temperature=0.7,
            max_tokens=50,
            timeout=30,
            retries=2,
            retry_delay=2
        ))
    
    # OpenRouter
    if os.getenv("OPENROUTER_API_KEY"):
        test_models.append(LLMModelConfig(
            name="anthropic/claude-3-haiku",
            api_base="https://openrouter.ai/api/v1",
            api_key=os.getenv("OPENROUTER_API_KEY"),
            temperature=0.7,
            max_tokens=50,
            timeout=30,
            retries=2,
            retry_delay=2
        ))
    
    return test_models


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª OpenEvolve API é…ç½®æµ‹è¯•å·¥å…·")
    print("=" * 50)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not check_env_vars():
        return
    
    # æµ‹è¯•ç¯å¢ƒå˜é‡ä¸­çš„APIå¯†é’¥
    print("\n=== æµ‹è¯•ç¯å¢ƒå˜é‡ä¸­çš„APIé…ç½® ===")
    test_models = create_test_models()
    
    if not test_models:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯æµ‹è¯•çš„APIå¯†é’¥")
        return
    
    success_count = 0
    for model in test_models:
        provider = model.name.split("-")[0].upper()
        success = await test_api_connection(provider, model)
        if success:
            success_count += 1
    
    print(f"\nğŸ“Š ç¯å¢ƒå˜é‡æµ‹è¯•ç»“æœ: {success_count}/{len(test_models)} ä¸ªAPIå¯ç”¨")
    
    # æµ‹è¯•é…ç½®æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    config_files = [
        "config.yaml",
        "configs/default_config.yaml",
        "examples/circle_packing/config_phase_1.yaml"
    ]
    
    for config_file in config_files:
        config_path = project_root / config_file
        if config_path.exists():
            await test_config_file(config_path)
            break
    
    print("\nâœ… æµ‹è¯•å®Œæˆ!")
    print("\nğŸ’¡ æç¤º:")
    print("- å¦‚æœæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®")
    print("- ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸")
    print("- æ£€æŸ¥APIé…é¢æ˜¯å¦å……è¶³")
    print("- å‚è€ƒ docs/api_configuration.md è·å–è¯¦ç»†é…ç½®è¯´æ˜")


if __name__ == "__main__":
    asyncio.run(main()) 